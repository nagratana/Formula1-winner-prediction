# ğŸï¸ Formula 1 Win Probability Predictor

> Predict the winning probability of any F1 driver for a specific **Grand Prix & Season** using historical race and qualifying data.

---

## ğŸš€ Project Overview

This project uses **Machine Learning (XGBoost â€“ Tuned with GridSearchCV)** to predict the probability of a driver winning a particular race based on:

- Qualifying position
- Grid position
- Race track (Grand Prix)
- Season (Year)
- Historical performance

---

## ğŸ§  Models & Techniques Used

| Step | Method |
|------|--------|
| Data Preprocessing | Merge + Feature Engineering |
| Models Tried | Logistic Regression, Random Forest, XGBoost |
| Best Model | âœ… XGBoost with Hyperparameter Tuning |
| Evaluation | Accuracy, F1 Score, ROC-AUC, Confusion Matrix |
| Final Output | Win probability based on user input |

---

## â­ Key Features

âœ… Predict **win probability** for a driver in a particular race & year  
âœ… User can input driver last name, race name, and year  
âœ… Automatically fetches grid & qualifying position from dataset  
âœ… No warnings, clean & optimized prediction pipeline  
âœ… Supports unseen race/driver scenarios safely  

---

## ğŸ“‚ Dataset Used

| File | Description |
|------|-------------|
| `drivers.csv` | Driver info |
| `races.csv` | Race + year data |
| `results.csv` | Race results + grid positions |
| `qualifying.csv` | Qualifying positions |

Dataset Source: Kaggle â€“ Formula 1 World Championship Data 1950-2024

---

## ğŸ”— Kaggle Notebook (Project Code)

ğŸ‘‰ https://www.kaggle.com/code/nagratna5207/ml-project-nagratna

---

## ğŸ› ï¸ Technologies Used

- Python
- Pandas, NumPy
- Scikit-Learn
- XGBoost
- Matplotlib, Seaborn
- Jupyter Notebook

---

## ğŸ Sample Output

